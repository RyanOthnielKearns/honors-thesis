#daily-notes #outline
___
In prep for the outline, what are the facts?
1. Lots of XAI papers take for granted that one of the end goals of explainable AI is *trustworthy* AI (notably [[Ribiero et al. 2016, "'Why Should I Trust You?' Explaning the Predictions of Any Classifier" - Reading Notes|Ribiero et al. 2016]], ==look for others==)
2. In particular, there are assertions that we *reach* trustworthiness either through *explainability* ([[Ribiero et al. 2016, "'Why Should I Trust You?' Explaning the Predictions of Any Classifier" - Reading Notes|Ribiero et al. 2016]]) or through *transparency* (==cite???==)
3. But what *is* trustworthiness, restricted to this XAI scope? In particular, what constitute the necessary and sufficient conditions required for us to attribute *trustworthiness* to some artificial intelligence agent $A$?
4. Where can we look for foundational work on trust that might help answer this question?
5. For one, there's the mainstream philosophical take on trust. According to [[McLeod 2015, "Trust" - Reading Notes|McLeod 2015]],